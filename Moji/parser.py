# moji/parser.py

# Importa todos os nÃ³s que o Parser pode construir
from .ast_nodes import (
    Node, ProgramNode, BlockNode, NumberNode, StringNode, VarAccessNode,
    BinOpNode, UnaryOpNode, VarDeclareNode, VarAssignNode, PrintNode,
    ReadNode, IfNode, FuncDefNode, ReturnNode, ListAppendNode,
    ListRemoveNode, ImportNode, SaveNode, SleepNode
)
# Importa todos os tipos de token que o Parser precisa reconhecer
from .token import (
    TT_PROGRAM_START, TT_PROGRAM_END, TT_BLOCK_START, TT_BLOCK_END,
    TT_KEYWORD_INT, TT_KEYWORD_REAL, TT_KEYWORD_STRING, TT_KEYWORD_LIST,
    TT_KEYWORD_READ, TT_KEYWORD_PRINT, TT_OP_PLUS, TT_OP_MINUS,
    TT_OP_MUL, TT_OP_DIV, TT_ASSIGN, TT_END_STATEMENT, TT_KEYWORD_IF,
    TT_KEYWORD_ELIF, TT_KEYWORD_ELSE, TT_KEYWORD_FUN, TT_KEYWORD_RETURN,
    TT_COMP_EQ, TT_COMP_GT, TT_COMP_LT, TT_LOGIC_NOT, TT_KEYWORD_APPEND,
    TT_KEYWORD_REMOVE, TT_KEYWORD_IMPORT, TT_KEYWORD_SAVE, TT_KEYWORD_SLEEP,
    TT_IDENTIFIER, TT_LIT_INT, TT_LIT_REAL, TT_LIT_STRING, TT_EOF
)


################################################################################
# 1. ERRO DE SINTAXE
################################################################################

class SyntaxError(Exception):
    def __init__(self, message):
        super().__init__(f"Erro de Sintaxe: {message}")


################################################################################
# 2. CLASSE PARSER
################################################################################

class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.token_idx = 0
        # Inicializa o token atual com o primeiro token da lista
        self.current_token = self.tokens[self.token_idx] if self.tokens else None

    def advance(self):
        """ AvanÃ§a para o prÃ³ximo token na lista. """
        self.token_idx += 1
        if self.token_idx < len(self.tokens):
            self.current_token = self.tokens[self.token_idx]
        else:
            # Se nÃ£o houver mais tokens, o token atual permanece o Ãºltimo (geralmente EOF)
            self.current_token = self.tokens[-1]
        return self.current_token

    def peek(self, n=1):
        """ Espia o token 'n' posiÃ§Ãµes Ã  frente sem avanÃ§ar. """
        peek_idx = self.token_idx + n
        if peek_idx < len(self.tokens):
            return self.tokens[peek_idx]
        return None

    def eat(self, expected_token_type):
        """
        Consome o token atual se ele for do tipo esperado.
        Se nÃ£o for, lanÃ§a um erro de sintaxe.
        """
        if self.current_token.type == expected_token_type:
            self.advance()
        else:
            raise SyntaxError(
                f"Esperava '{expected_token_type}', mas encontrou '{self.current_token.type}'"
            )

    # --- PONTO DE PARTIDA (NÃ­vel mais alto) ---

    def parse(self):
        """
        Inicia a anÃ¡lise sintÃ¡tica.
        Um programa Ã©: ğŸŒ± ...lista de comandos... ğŸŒ³
        """
        self.eat(TT_PROGRAM_START)

        # statements() vai ler todos os comandos atÃ© encontrar o ğŸŒ³
        statements = self.statements(end_token_type=TT_PROGRAM_END)

        # Se statements() parou e nÃ£o Ã© o ğŸŒ³, algo estÃ¡ errado
        self.eat(TT_PROGRAM_END)

        # Se chegou aqui e o prÃ³ximo token nÃ£o Ã© EOF, hÃ¡ cÃ³digo sobrando
        if self.current_token.type != TT_EOF:
            raise SyntaxError("CÃ³digo encontrado apÃ³s o fim do programa 'ğŸŒ³'.")

        return ProgramNode(statements)

    # --- COMANDOS (Statements) ---

    def statements(self, end_token_type):
        """
        Processa uma lista de comandos atÃ© encontrar um token final
        (ex: ğŸŒ³ para o programa, ğŸ“¦â›” para um bloco).
        """
        statement_list = []

        while self.current_token.type != end_token_type and self.current_token.type != TT_EOF:
            statement_list.append(self.statement())

        return statement_list

    def statement(self):
        """ Roteador: Decide qual tipo de comando estÃ¡ sendo lido. """
        token_type = self.current_token.type

        # ğŸ–¨ï¸ ... ğŸ”š (Print)
        if token_type == TT_KEYWORD_PRINT:
            return self.print_statement()

        # ğŸ‘€ ... ğŸ”š (Read)
        if token_type == TT_KEYWORD_READ:
            return self.read_statement()

        # ğŸ”¢, ğŸ’¬, ğŸ‘½, ğŸ“œ ... (DeclaraÃ§Ã£o de Var)
        if token_type in (TT_KEYWORD_INT, TT_KEYWORD_REAL, TT_KEYWORD_STRING, TT_KEYWORD_LIST):
            return self.var_declaration()

        # ğŸ¤” ... (If)
        if token_type == TT_KEYWORD_IF:
            return self.if_statement()

        # ğŸ“¦ ... ğŸ“¦â›” (Block)
        if token_type == TT_BLOCK_START:
            return self.block()

        # ğŸ§© ... (DefiniÃ§Ã£o de FunÃ§Ã£o)
        if token_type == TT_KEYWORD_FUN:
            return self.func_definition()

        # ğŸ”™ ... (Return)
        if token_type == TT_KEYWORD_RETURN:
            return self.return_statement()

        # âš™ï¸, ğŸ’¾, â±ï¸ (Comandos de Sistema)
        if token_type == TT_KEYWORD_IMPORT:
            return self.import_statement()
        if token_type == TT_KEYWORD_SAVE:
            return self.save_statement()
        if token_type == TT_KEYWORD_SLEEP:
            return self.sleep_statement()

        # Identificador (Pode ser AtribuiÃ§Ã£o ou Op de Lista)
        if token_type == TT_IDENTIFIER:
            next_token_type = self.peek().type

            # x ğŸ‘‰ ... ğŸ”š (AtribuiÃ§Ã£o)
            if next_token_type == TT_ASSIGN:
                return self.var_assignment()

            # myList â•ğŸ“œ ... ğŸ”š (List Append)
            if next_token_type == TT_KEYWORD_APPEND:
                return self.list_append()

            # myList â–ğŸ“œ ... ğŸ”š (List Remove)
            if next_token_type == TT_KEYWORD_REMOVE:
                return self.list_remove()

        # Se nÃ£o for nada disso, Ã© um erro.
        raise SyntaxError(f"Comando inesperado: token '{self.current_token}'")

    def print_statement(self):
        """ Processa: ğŸ–¨ï¸ <expressÃ£o> ğŸ”š """
        self.eat(TT_KEYWORD_PRINT)
        node_to_print = self.expression()
        self.eat(TT_END_STATEMENT)
        return PrintNode(node_to_print)

    def read_statement(self):
        """ Processa: ğŸ‘€ <identificador> ğŸ”š """
        self.eat(TT_KEYWORD_READ)
        var_token = self.current_token
        self.eat(TT_IDENTIFIER)
        self.eat(TT_END_STATEMENT)
        return ReadNode(var_token)

    def var_declaration(self):
        """ Processa: <tipo> <nome> [ğŸ‘‰ <expressÃ£o>] ğŸ”š """
        type_token = self.current_token
        self.advance()  # Consome o tipo (ğŸ”¢, ğŸ’¬, etc.)

        var_name_token = self.current_token
        self.eat(TT_IDENTIFIER)

        value_node = None
        # Verifica se Ã© uma declaraÃ§Ã£o com inicializaÃ§Ã£o
        if self.current_token.type == TT_ASSIGN:
            self.eat(TT_ASSIGN)
            value_node = self.expression()

        self.eat(TT_END_STATEMENT)
        return VarDeclareNode(type_token, var_name_token, value_node)

    def var_assignment(self):
        """ Processa: <nome> ğŸ‘‰ <expressÃ£o> ğŸ”š """
        var_name_token = self.current_token
        self.eat(TT_IDENTIFIER)
        self.eat(TT_ASSIGN)
        value_node = self.expression()
        self.eat(TT_END_STATEMENT)
        return VarAssignNode(var_name_token, value_node)

    def list_append(self):
        """ Processa: <nome_lista> â•ğŸ“œ <expressÃ£o> ğŸ”š """
        list_var_token = self.current_token
        self.eat(TT_IDENTIFIER)
        self.eat(TT_KEYWORD_APPEND)
        value_node = self.expression()
        self.eat(TT_END_STATEMENT)
        return ListAppendNode(list_var_token, value_node)

    def list_remove(self):
        """ Processa: <nome_lista> â–ğŸ“œ <expressÃ£o_indice> ğŸ”š """
        list_var_token = self.current_token
        self.eat(TT_IDENTIFIER)
        self.eat(TT_KEYWORD_REMOVE)
        index_node = self.expression()  # O Ã­ndice a ser removido
        self.eat(TT_END_STATEMENT)
        return ListRemoveNode(list_var_token, index_node)

    def if_statement(self):
        """ Processa: ğŸ¤” <cond> ğŸ“¦ ... ğŸ“¦â›” [ğŸ”€ <cond> ğŸ“¦ ... ğŸ“¦â›”]* [ğŸ¤¨ ğŸ“¦ ... ğŸ“¦â›”] """
        cases = []
        else_case = None

        # Bloco IF (obrigatÃ³rio)
        self.eat(TT_KEYWORD_IF)
        condition = self.expression()
        body = self.block()
        cases.append((condition, body))

        # Blocos ELIF (opcionais)
        while self.current_token.type == TT_KEYWORD_ELIF:
            self.eat(TT_KEYWORD_ELIF)
            condition = self.expression()
            body = self.block()
            cases.append((condition, body))

        # Bloco ELSE (opcional)
        if self.current_token.type == TT_KEYWORD_ELSE:
            self.eat(TT_KEYWORD_ELSE)
            else_case = self.block()

        return IfNode(cases, else_case)

    def block(self):
        """ Processa: ğŸ“¦ <lista_de_comandos> ğŸ“¦â›” """
        self.eat(TT_BLOCK_START)
        # statements() vai ler tudo atÃ© encontrar o ğŸ“¦â›”
        statements_list = self.statements(end_token_type=TT_BLOCK_END)
        self.eat(TT_BLOCK_END)
        return BlockNode(statements_list)

    def func_definition(self):
        """ Processa: ğŸ§© <nome> [arg1] [arg2] ... ğŸ“¦ ... ğŸ“¦â›” """
        self.eat(TT_KEYWORD_FUN)

        func_name_token = self.current_token
        self.eat(TT_IDENTIFIER)

        arg_name_tokens = []
        # Continua lendo nomes de argumentos atÃ© encontrar o ğŸ“¦
        while self.current_token.type == TT_IDENTIFIER:
            arg_name_tokens.append(self.current_token)
            self.eat(TT_IDENTIFIER)

        body_node = self.block()
        return FuncDefNode(func_name_token, arg_name_tokens, body_node)

    def return_statement(self):
        """ Processa: ğŸ”™ [<expressÃ£o>] ğŸ”š """
        self.eat(TT_KEYWORD_RETURN)

        node_to_return = None
        # Se houver algo para retornar (nÃ£o Ã© sÃ³ "ğŸ”™ ğŸ”š")
        if self.current_token.type != TT_END_STATEMENT:
            node_to_return = self.expression()

        self.eat(TT_END_STATEMENT)
        return ReturnNode(node_to_return)

    # Comandos de sistema (simples)
    def import_statement(self):
        self.eat(TT_KEYWORD_IMPORT)
        module_name_token = self.current_token
        self.eat(TT_IDENTIFIER)  # Assumindo que importamos pelo nome
        self.eat(TT_END_STATEMENT)
        return ImportNode(module_name_token)

    def save_statement(self):
        self.eat(TT_KEYWORD_SAVE)
        data_node = self.expression()
        filename_node = self.expression()  # Ex: ğŸ’¾ variavel "arquivo.txt" ğŸ”š
        self.eat(TT_END_STATEMENT)
        return SaveNode(data_node, filename_node)

    def sleep_statement(self):
        self.eat(TT_KEYWORD_SLEEP)
        duration_node = self.expression()
        self.eat(TT_END_STATEMENT)
        return SleepNode(duration_node)

    # --- EXPRESSÃ•ES (PrecedÃªncia de Operadores) ---

    def binary_operation(self, func_to_call, valid_op_types):
        """
        FunÃ§Ã£o auxiliar genÃ©rica para processar operaÃ§Ãµes binÃ¡rias
        (como 1 â• 2, ou 10 âš–ï¸ x)
        """
        left = func_to_call()

        while self.current_token.type in valid_op_types:
            op_token = self.current_token
            self.eat(op_token.type)
            right = func_to_call()
            left = BinOpNode(left, op_token, right)

        return left

    def expression(self):
        """ Ponto de entrada para qualquer expressÃ£o. (NÃ­vel mais baixo de precedÃªncia) """
        # Por enquanto, apenas comparaÃ§Ãµes. Poderia expandir para 'E' e 'OU' lÃ³gicos.
        return self.comparison()

    def comparison(self):
        """ Processa: âš–ï¸, â¬†ï¸, â¬‡ï¸ """
        return self.binary_operation(self.term, (TT_COMP_EQ, TT_COMP_GT, TT_COMP_LT))

    def term(self):
        """ Processa: â•, â– """
        return self.binary_operation(self.factor, (TT_OP_PLUS, TT_OP_MINUS))

    def factor(self):
        """ Processa: âœ–ï¸, â— """
        return self.binary_operation(self.unary, (TT_OP_MUL, TT_OP_DIV))

    def unary(self):
        """ Processa: ğŸš« """
        if self.current_token.type == TT_LOGIC_NOT:
            op_token = self.current_token
            self.eat(TT_LOGIC_NOT)
            node = self.unary()  # Chamada recursiva para permitir 'ğŸš«ğŸš«x'
            return UnaryOpNode(op_token, node)
        return self.atom()

    def atom(self):
        """
        Processa os "Ã¡tomos" da gramÃ¡tica: nÃºmeros, strings, nomes de vars.
        (NÃ­vel mais alto de precedÃªncia).
        """
        token = self.current_token

        if token.type == TT_LIT_INT or token.type == TT_LIT_REAL:
            self.eat(token.type)
            return NumberNode(token)

        elif token.type == TT_LIT_STRING:
            self.eat(TT_LIT_STRING)
            return StringNode(token)

        elif token.type == TT_IDENTIFIER:
            self.eat(TT_IDENTIFIER)
            return VarAccessNode(token)  # Acesso a uma variÃ¡vel

        # Se nÃ£o for nada disso, Ã© um erro de sintaxe na expressÃ£o
        raise SyntaxError(f"Esperava um Inteiro, Real, String ou Identificador, mas encontrou: {token}")


################################################################################
# 3. Bloco de Teste
# (Para executar este arquivo diretamente: python -m moji.parser)
################################################################################

if __name__ == '__main__':
    # Precisamos do Lexer para gerar os tokens primeiro
    from .lexer import Lexer

    # CÃ³digo de exemplo do seu "hello_world.moji"
    test_code = """
    ğŸŒ± ğŸ’­ Este Ã© um programa de teste!

    ğŸ’¬ meuNome ğŸ‘‰ "Moji" ğŸ”š
    ğŸ–¨ï¸ "OlÃ¡, " â• meuNome ğŸ”š

    ğŸ”¢ x ğŸ‘‰ 10 ğŸ”š
    ğŸ¤” x âš–ï¸ 10 ğŸ“¦
        ğŸ–¨ï¸ "x Ã© 10!" ğŸ”š
    ğŸ“¦â›”

    ğŸŒ³
    """

    print(f"--- Testando Parser com o cÃ³digo: ---\n{test_code}")

    try:
        # 1. Lexer
        lexer = Lexer(test_code)
        tokens = lexer.make_tokens()
        print("--- Tokens Gerados (pelo Lexer) ---")
        for t in tokens:
            print(t)

        # 2. Parser
        parser = Parser(tokens)
        ast = parser.parse()

        print("\n--- AST Gerada (pelo Parser) ---")
        print(ast)

    except Exception as e:
        print(f"\n!!! ERRO NO PARSER: {e}")